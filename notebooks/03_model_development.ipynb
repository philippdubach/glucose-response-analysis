# Cell 1: Setup
import sys
from pathlib import Path
sys.path.append(str(Path.cwd().parent / 'src'))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from src.features.feature_engineering import EnhancedFeatureEngineer
from src.models.xgboost_regressor import GlucoseXGBoostRegressor, MultiLinearRegressor
from src.visualization.plotting import GlucosePlotter

# Cell 2: Feature Engineering
feature_engineer = EnhancedFeatureEngineer()

# Load fitted parameters (from previous notebook)
# df_fitted_params = pd.read_csv('../results/fitted_parameters.csv')

# Create comprehensive ML dataset
df_ml = feature_engineer.prepare_complete_ml_dataset(df_fitted_params)

print(f"ML dataset shape: {df_ml.shape}")
print(f"Features: {df_ml.columns.tolist()}")

# Cell 3: Feature analysis
# Correlation matrix for key features
key_features = ['A', 'delta', 'sigma', 'CHO', 'PRO', 'FAT', 'age', 'BMI']
available_features = [f for f in key_features if f in df_ml.columns]

if len(available_features) > 1:
    plt.figure(figsize=(10, 8))
    correlation_matrix = df_ml[available_features].corr()
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)
    plt.title('Feature Correlation Matrix')
    plt.show()

# Cell 4: XGBoost Model Training
xgboost_regressor = GlucoseXGBoostRegressor()

# Train models for all targets
model_results = xgboost_regressor.train_all_targets(df_ml, hyperparameter_tuning=False)

# Display results
for target_name, results in model_results.items():
    print(f"\n{target_name.upper()} Results:")
    print(f"Train R²: {results['train_metrics']['r_squared']:.3f}")
    print(f"Test R²: {results['test_metrics']['r_squared']:.3f}")
    print(f"Test RMSE: {results['test_metrics']['rmse']:.3f}")
    print(f"Test MAE: {results['test_metrics']['mae']:.3f}")
    print(f"Correlation: {results['test_metrics']['correlation']:.3f} "
          f"(p={results['test_metrics']['p_value']:.4f})")

# Cell 5: Model Visualization
plotter = GlucosePlotter()

# Plot model performance
plotter.plot_model_performance(model_results)

# Bland-Altman plots
for target_name in model_results.keys():
    bland_altman_data = xgboost_regressor.create_bland_altman_analysis(target_name)
    plotter.plot_bland_altman(bland_altman_data, target_name)

# Cell 6: Multi-linear Regression Model
mlr = MultiLinearRegressor()
mlr_results = mlr.train(df_ml)

print("\nMulti-linear Regression Results:")
print(f"R²: {mlr_results['r2']:.3f}")
print(f"RSE: {mlr_results['rse']:.2f} mg/dL")
print("\nCoefficients:")
for feature, coef in mlr_results['coefficients'].items():
    p_val = mlr_results['p_values'][feature]
    significance = "***" if p_val < 0.001 else "**" if p_val < 0.01 else "*" if p_val < 0.05 else ""
    print(f"{feature}: {coef:.4f} {significance} (p={p_val:.4f})")

# Cell 7: Feature Importance (SHAP Analysis)
if len(df_ml) > 50:  # Only if we have enough samples
    for target_name in model_results.keys():
        print(f"\nCalculating SHAP values for {target_name}...")
        
        # Sample data for SHAP analysis (computationally expensive)
        X_sample = df_ml.sample(min(100, len(df_ml)))
        X_features, _ = xgboost_regressor.prepare_features(X_sample)
        
        shap_values = xgboost_regressor.calculate_shap_values(X_features, target_name)
        plotter.plot_shap_values(shap_values, X_features, target_name)

# Cell 8: Generate comprehensive report
plotter.create_comprehensive_report(df_fitted_params, model_results, df_ml, xgboost_regressor)

# Cell 9: Save results
results_path = Path('../results')
results_path.mkdir(exist_ok=True)

# Save datasets
df_fitted_params.to_csv(results_path / 'fitted_parameters.csv', index=False)
df_ml.to_csv(results_path / 'ml_dataset.csv', index=False)

# Save models
xgboost_regressor.save_models(results_path / 'models')

print(f"\nResults saved to {results_path}")